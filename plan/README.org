#+TITLE: VLDB 投稿改进计划
#+AUTHOR: 崔延宣
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [11pt,a4paper]
#+LaTeX_HEADER: \usepackage{minted}
#+LaTeX_HEADER: \usepackage{fullpage}
#+LaTeX_HEADER: \usepackage{fancyvrb}
#+LaTeX_HEADER: \usepackage{enumitem}
#+LaTeX_HEADER: \usepackage{xeCJK}
#+LaTeX_HEADER: \usepackage{bbding}
#+LaTeX_HEADER: \usepackage{amsthm}
#+LaTeX_HEADER: \newtheorem{theorem}{Theorem}
#+LaTeX_HEADER: \newtheorem{lemma}{Lemma}
#+LaTeX_HEADER: \newtheorem{definition}{Definition}
#+LaTeX_HEADER: \usepackage{centernot}
#+LaTeX_HEADER: \usepackage{indentfirst}
#+LaTeX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \usepackage{array}
#+LaTeX_HEADER: \usepackage{booktabs}
#+LaTeX_HEADER: \usepackage[linesnumbered,ruled,noend]{algorithm2e}
#+LaTeX_HEADER: \usepackage{siunitx}
#+LaTeX_HEADER: \setlength\parindent{2em}
#+OPTIONS: toc:nil

* Introduction
  - 在图结构中，形如 $u_1 \leftrightarrows u_2$ 的这种 2-cycle 结构是一种很常见的模式，
    例如在社交网络中它可以表示互相关注的朋友关系。
    #+NAME: tab:2-cycle
    #+CAPTION: 数据图统计信息
    |------------------+---------------+---------------+-----------+------------|
    |                  | $\mid V \mid$ | $\mid E \mid$ | # 2-cycle |      ratio |
    |------------------+---------------+---------------+-----------+------------|
    | soc-Epinions1    |         75879 |        508837 |    103097 | 0.25409622 |
    | web-BerkStan     |        685230 |       7600595 |    951125 | 0.14303772 |
    | web-Google       |        875713 |       5105039 |    782988 | 0.18116121 |
    | soc-LiveJournal1 |       4847571 |      68993773 |  25624154 | 0.59083189 |
    |------------------+---------------+---------------+-----------+------------|
    #+TBLFM: @2$5..@>$5 = $4 / ($3 - $4)
    现有的图存储方案（CSR、CSC、链表）出边、入边信息存在分裂，匹配含有 2-cycle 结构的模式图需要很大的开销：
    一种做法是分别匹配 $u_1 \rightarrow u_2$ 和 $u_2 \rightarrow u_1$ 再做 join；
    另一种做法是匹配 $u_1 \rightarrow u_2$ 同时检查是否存在 $u_2 \rightarrow u_1$ 的边。
    这两种做法最坏时间复杂度都是 $O(m^2)$
    （其中 $m$ 是数据图中边的条数，由于出、入边拓扑是分裂的，无法事先知道数据图中的某个节点是否具有 2-cycle 结构，
    因此匹配时需要对所有待匹配节点的出边、入边进行检查，而不仅仅是表[[tab:2-cycle]]中 2-cycle 那部分。）
    为了解决这一问题，我们设计了一种新的 vertex-centric 数据图存储模型，将出边、入边信息直接和节点绑定到一起，
    可以在 $O(m)$ 的时间复杂度通过磁盘顺序扫描同时检查出边和入边的拓扑完成 2-cycle 的匹配。
    /（突出 vertex-centric 的不同，单独作为一点）/
  - 基于 vertex-centric 数据图存储模型，我们设计了一种基于星形子图匹配的通用属性图匹配方法。
    现有的基于星形子图的匹配方案例如 STwig 由于叶子节点匹配结果的枚举会带来超线性中间结果膨胀，
    TwinTwig 限制星形图最多只有两个叶子节点，但这也只能缓解膨胀问题。
    为了解决中间结果的存储膨胀问题，factorized representation 和 VCBC 对行存储的中间结果进行压缩表示，
    只需枚举 vertex-cover 的匹配结果，其他节点可以用数组的方式紧凑存储，
    但仅枚举 vertex-cover 也是会带来不小的中间结果膨胀，VCBC 发现 390MB 的数据图可以产生 245TB 的压缩中间结果（超线性膨胀）。
    为了从根本上解决中间结果膨胀，我们基于 VCBC 限制 vertex-cover 只能有一个节点（即星形图）设计了 SuperRow 存储格式，
    SuperRow 可以保证最坏情况下也只会出现线性膨胀（实验中所有的中间结果都没有比数据图大）。
    为了提高外存效率，我们为 SuperRow 设计了空间预分配策略，只需磁盘顺序读写即可完成星形图的匹配。
    利用 vertex-centric 节点存储的有序性，SuperRow 可以高效地 zero-copy merge join 以获取最终结果。
    /（WHERE 语句在正文中提一下，由于 Reviewer 2 不看好 SuperRow，我们不再压缩单独作为一点，把它和星形子图分解放到一起。）/
  - 为了加速匹配过程中节点的查找，我们为 vertex-centric 存储模型设计了 global/local 两种索引结构。
    全局索引比较平凡，对图中的节点根据标签分组建立索引。
    数据图通常都符合 power-law，图中某些节点的出度或入度可以非常巨大，但具体的匹配问题只关心这些名人节点具有特定标签的邻接点，
    因此匹配时没必要对所有的邻接点都进行遍历，
    我们的局部索引对邻接点根据标签进行分组，每个节点都有一个局部索引和它在一起存储，通过局部索引可以减少不必要的磁盘读。
    /（由于 Reviewer 1 和 3 都想看看不同 label 个数的影响，所以把 index 单独拎出来作为一点和后面的实验进行呼应）。/
* 实验
  1. 整体性能对比（Graphflow、CFL、Neo4j），并保留现有实验的：
     - 压缩率
     - 谓词下推
     - join 测试
  2. vertex-centric vs. CSR，重点比较匹配 $u_1 \leftrightarrows u_2$ 的差距
  3. 局部索引性能提升（设置不同的 label 数与没有局部索引的进行对比）
  4. 星形子图分解改进提升
  5. 不同星形子图分解方法的影响
