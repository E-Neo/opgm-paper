\section{Vertex-Centric Storage for Property Graph}\label{sec:storage}
%The random access problem is a well known hard problem for out-of-core systems, especially for the graph related problem, which is notorious for its poor locality~\cite{DBLP:conf/osdi/KyrolaBG12}.

Many graph computing frameworks store graphs on disk using the double list method:
storing the in-edges and out-edges \textbf{separately} in different lists for each vertex,
via the compressed sparse column (CSC) and the compressed sparse row (CSR) format~\cite{DBLP:conf/sc/PearceGA10}.
%TODO:分别简述一下CSC和CSR都是怎么做的
However, this separation incurs excessive random access on property graphs because we need to get the information for in/out edges during pattern matching.

Instead, SeqStar stores the graph data in a vertex-centric way which stores all the information related to one vertex \textbf{together}.
With small indexes on disks, one can quickly get the correct addresses of relevant data on disk during pattern matching. Because all the related information is stored together, SeqStar can make sure that all disk reads are sequential.

Moreover, by using the property graph matching engine that will be discussed in the next section,
the huge data graph will be loaded at most once.
\subsection{Scan the Data Graph Sequentially}
%The property graph matching problem requires the complete connection information between vertices,
%however, the conventional double list storage method break up the completeness and results in random disk accesses.

Consider the example in Figure~\ref{img:running_example}.
If two vertices in the data graph, say $v_i$ and $v_j$, are supposed to match $u_1$ and $u_2$,
we must be sure that $v_i$ and $v_j$ follow each other at the same time.
This kind of neighbor checking is the most essential building block in a property graph matching engine.

In the data graph, vertex $1$ has $4$ in-edges and $7$ out-edges.
Suppose that they are stored separately as in the traditional way.
In order to determine whether vertex $1$ could match $u_1$,
one has to scan the in-edges (or equally, the out-edges) of vertex $1$ and then check whether the visited neighbor is in the out-edges (or in-edges) list.
Such a scan-and-check method would significantly slow down the graph matching process,
because the checking process results in many random disk reads.
For large power-law graphs such as social media graphs, where the celebrities or trending topics have a huge amount of followers, this phenomenon greatly exacerbate the random access problem.
%the in/out-edges lists stored on disk have to be swapped in and out frequently during the scan and check process as a result of the random disk access pattern.
%% Multiple edges between $u_1$ and $u_2$ make things even worse.
%And it would be more complicated if there are more than two edges between $u_1$ and $u_2$ in the pattern graph.

On the contrary, SeqStor's vertex-centric storage keeps the necessary connection information associated with one vertex together for graph matching.
Figure~\ref{img:data_example} shows the logical structure for the data graph in Figure~\ref{img:running_example}.
The specific edge information (direction, types) could be obtained by the stored edge labels, i.e., the top labels associated to the out-edges and the bottom labels associated to the in-edges (Figure~\ref{img:data_example}).

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{img/data_example.pdf}
  \caption{Vertex-centric graph data storage.}\label{img:data_example}
\end{figure}

By using the vertex centric graph data storage, the neighborhood checking process can be accomplished efficiently within a sequential disk scan.
For $S_1$ in Figure~\ref{img:running_example},
to check the neighbors of vertex $1$, SeqStar scans the neighbors $2, 3, 5, 6$ and $4, 7, 9$ sequentially.
No random disk access appears during the whole process.
\subsection{Graph Data Indexes}
%Despite of the fact that the size of the whole data graph could be gigantic,we may only care a fraction of the graph by specify the labels in our query for a concrete graph matching problem.
There are two basic operations provided by the graph storage engine:
(1) Given a data vertex, retrieve its neighbors with a specific label;
(2) Given a vertex label, retrieve the vertices with the label. In the implementation level, the first operation is supported by the \emph{local index} and the second operation is supported by the \emph{global index}.
%% In the following paragraphs, we'll show how to make the two operations efficiently by adding a few simple but efficient indices to the vertex-centric storage engine,
%% which reduces the searching space and I/O significantly.

Consider the data graph in Figure~\ref{img:running_example}.
One may want to study only the relationships among users.
For vertex $1$ in the figure,
no matter how much social media she has published or viewed, we could just ignore all of them in this specific problem.
%% A straightforward idea is to group the neighbor vertices with the same label together when storing the vertices.
%% However, if the neighbor vertices were stored in the traditional in/out-edge double lists method,
%% we have to group them twice and then still face the information insufficient problem as we discussed in the previous subsection.
%% As for our vertex-centric storage method,
For SeqStor's vertex-centric storage,
we can build the index as in Figure~\ref{img:data_example}.
These indexes are key-value pairs mapping the vertex labels to the starting/ending positions of the neighbors on disk.
Since it is used to locate only the neighbors of a specific vertex, we refer to this kind of index as \emph{local index}.
With the help of local index, we can skip all the unnecessary neighbors and only scan the necessary ones.
%% \begin{figure}[ht]
%%   \centering
%%   \includegraphics[width=0.48\textwidth]{img/data_neighbors.pdf}
%%   \caption{The vertex-centric storage structure of the celebrity $v_1$ in Figure~\ref{img:celebrity_star}.}\label{img:data_neighbors}
%% \end{figure}

%From a higher perspective, in order to solve a property graph matching problem,

To begin a match, one need to firstly select a root vertex in the data graph.
%% regardless of the concrete graph matching algorithm whether it is tree based or join based.
%There is no need to scan all the vertices in a billion node data graph if we only care about vertices with the specific labels.
%Just like the local index we discussed above, we could add a global index which
To this end, a \emph{global index} is constructed to contain key-value pairs that maps the labels to the their corresponding positions on disk (Figure~\ref{img:data_example}).

The sizes of indexes in SeqStar are relatively smaller than existing works which have a super-linear index problem~\cite{DBLP:journals/pvldb/SunWWSL12}. The sizes of indexes grow \emph{super-linearly} with respect to the \emph{edges}.
In contrast, indexes of SeqStar grows \emph{linearly} with respect to the \emph{vertices}.
The size of the global index is the same as the number of vertex labels ($l$). The size of local indexes is bounded to $l \times n$ ($n$ is the number of vertices).
%% In summery, for a property graph matching problem, we could quickly jump to the domain of interest with the help of the global index, and then scan and check only the necessary neighbors with the help of our local index.
%% After jump to the correct position, all the disk reads are sequential.
%% \begin{figure}[ht]
%%   \centering
%%   \includegraphics[width=0.48\textwidth]{img/data_vertices.pdf}
%%   \caption{The storage structure overview of the data graph in Figure~\ref{img:celebrity_star}.}\label{img:data_vertices}
%% \end{figure}
\subsection{Iterators over Graph Storage}\label{sec:storage_iterators}
Applications need to perform two basic operations (visiting vertices and visiting the neighbors) on the graph data storage.
We define two iterators as the interface to visit the data graph:
\begin{enumerate}[noitemsep]
\item \textsc{VertexIter} iterates the vertices with the given label, ordered by vertex IDs\@.
%Given a vertex label, it iterates through the vertices with the specified label ordered by the ID of vertices;
\item \textsc{NeighborIter} iterates the neighbors of a given vertex to match a given label. The neighbors are sorted by their vertex IDs.

%Given a data vertex and a label, it visits the neighbors with the label, the neighbors are also sorted by the IDs.
\end{enumerate}
%% In Section~\ref{sec:match} we'll show that the sorting constraint could boost the matching of property graphs.

These iterators could be implemented efficiently by using SeqStar's vertex-centric storage model.
Figure~\ref{img:data_graph} shows the on-disk layout of this model.
Vertices are sorted by their IDs. We also store in/out-degrees for early filters when scanning the vertices.
Edge labels are stored as integers here (alternatively, bitmap could also be used if only a small number of labels need to support).
The \textsc{VertexIter} searches the global index and then visits the disk data sequentially.
The \textsc{NeighborIter} scans the neighbors with the help of the local index.

%% Note that the vertex-centric storage model is not restricted to this disk format.
%% In fact, as long as a storage engine could implement the two iterators efficiently,
%% it could implement the vertex-centric storage model well.
%% For example, the sorted vertices could be replaced with B-tree to make the insertion/deletion operation easier for dynamic graphs.
%% It is also possible to implement the vertex-centric storage model in memory as buffer cache for existing graph databases to achieve better locality.
%% Moreover, we are now working on implementing the vertex-centric storage model on top of relational database to embrace the power of the half-century-year-old mature technology.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.48\textwidth]{img/data_graph.pdf}
%  \caption{An I/O efficient property graph storage method that can boost the graph matching process.}
  \caption{On-disk layout of vertex-centric storage model.}\label{img:data_graph}
\end{figure}
